"""
Adaptive Refactor Engine - –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–∞—è –º–æ–¥–µ—Ä–Ω–∏–∑–∞—Ü–∏—è –∫–æ–¥–∞.

–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:
- Code smell detection
- Pattern modernization (legacy ‚Üí modern)
- Interface updates (type hints, docstrings)
- Test generation
- Backward compatibility preservation
"""

import ast
import logging
import re
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Any, Optional, Set
import json

logger = logging.getLogger(__name__)


@dataclass
class RefactorProposal:
    """–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –ø–æ —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥—É."""
    id: str
    target_file: str
    refactor_type: str  # 'modernize', 'simplify', 'optimize', 'document'
    old_pattern: str
    new_pattern: str
    reasoning: str
    affected_lines: List[int]
    risk_score: float
    backward_compatible: bool
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            'id': self.id,
            'target_file': self.target_file,
            'refactor_type': self.refactor_type,
            'old_pattern': self.old_pattern,
            'new_pattern': self.new_pattern,
            'reasoning': self.reasoning,
            'affected_lines': self.affected_lines,
            'risk_score': self.risk_score,
            'backward_compatible': self.backward_compatible
        }


class AdaptiveRefactorEngine:
    """
    –î–≤–∏–∂–æ–∫ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥–∞.
    
    –û–ø–µ—Ä–∞—Ü–∏–∏:
    1. Detect legacy patterns
    2. Propose modern alternatives
    3. Update interfaces (type hints, docs)
    4. Generate tests
    5. Ensure backward compatibility
    """
    
    # Patterns –¥–ª—è –º–æ–¥–µ—Ä–Ω–∏–∑–∞—Ü–∏–∏
    LEGACY_PATTERNS = {
        # Sync ‚Üí Async (–≥–¥–µ —É–º–µ—Å—Ç–Ω–æ)
        r'def\s+(\w+)\(([^)]*)\):\s*\n\s+""".*?"""\s*\n\s+time\.sleep': {
            'modern': 'async def {func}({params}):\n    """..."""\n    await asyncio.sleep',
            'reasoning': 'Async improves concurrency'
        },
        
        # String formatting: % ‚Üí f-strings
        r'["\'].*?%[sd].*?["\']\s*%\s*\(': {
            'modern': 'f"...{var}..."',
            'reasoning': 'f-strings more readable and faster'
        },
        
        # Dict.get() instead of try/except KeyError
        r'try:\s*\n\s+.*?\[([^]]+)\]\s*\n\s*except KeyError:': {
            'modern': '.get({key}, default)',
            'reasoning': 'More Pythonic error handling'
        }
    }
    
    def __init__(
        self,
        src_dir: str = "src/legion",
        preserve_compatibility: bool = True
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Adaptive Refactor Engine.
        
        Args:
            src_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –∏—Å—Ö–æ–¥–Ω–∏–∫–∞–º–∏
            preserve_compatibility: –°–æ—Ö—Ä–∞–Ω—è—Ç—å backward compatibility
        """
        self.src_dir = Path(src_dir)
        self.preserve_compatibility = preserve_compatibility
        
        logger.info("‚úÖ AdaptiveRefactorEngine initialized")
        logger.info(f"   Backward compatibility: {preserve_compatibility}")
    
    def analyze_codebase(self) -> List[RefactorProposal]:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–æ–¥–æ–≤—É—é –±–∞–∑—É –∏ –Ω–∞–π—Ç–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥–∞.
        
        Returns:
            –°–ø–∏—Å–æ–∫ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –ø–æ —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥—É
        """
        logger.info("üîç Analyzing codebase for refactoring opportunities...")
        
        proposals = []
        
        for py_file in self.src_dir.rglob("*.py"):
            if '__pycache__' in str(py_file):
                continue
            
            file_proposals = self._analyze_file(py_file)
            proposals.extend(file_proposals)
            
            if file_proposals:
                logger.debug(f"   {py_file.name}: {len(file_proposals)} proposals")
        
        logger.info(f"   Found {len(proposals)} refactoring opportunities")
        
        return proposals
    
    def _analyze_file(self, file_path: Path) -> List[RefactorProposal]:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª.
        
        Args:
            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
        
        Returns:
            –°–ø–∏—Å–æ–∫ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        """
        proposals = []
        
        try:
            code = file_path.read_text()
            tree = ast.parse(code)
            
            # Check for missing type hints
            proposals.extend(self._find_missing_type_hints(file_path, tree, code))
            
            # Check for missing docstrings
            proposals.extend(self._find_missing_docstrings(file_path, tree, code))
            
            # Check for legacy patterns
            proposals.extend(self._find_legacy_patterns(file_path, code))
            
            # Check for complex functions
            proposals.extend(self._find_complex_functions(file_path, tree, code))
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Failed to analyze {file_path}: {e}")
        
        return proposals
    
    def _find_missing_type_hints(self, file_path: Path, tree: ast.AST, code: str) -> List[RefactorProposal]:
        """
        –ù–∞–π—Ç–∏ —Ñ—É–Ω–∫—Ü–∏–∏ –±–µ–∑ type hints.
        
        Args:
            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
            tree: AST –¥–µ—Ä–µ–≤–æ
            code: –ò—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥
        
        Returns:
            –°–ø–∏—Å–æ–∫ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        """
        proposals = []
        
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                # Check if missing return type
                if node.returns is None and node.name != '__init__':
                    proposals.append(RefactorProposal(
                        id=f"type_hint_{file_path.stem}_{node.name}",
                        target_file=str(file_path),
                        refactor_type='document',
                        old_pattern=f"def {node.name}(",
                        new_pattern=f"def {node.name}(...) -> ReturnType:",
                        reasoning="Add type hints for better IDE support and type checking",
                        affected_lines=[node.lineno],
                        risk_score=0.1,
                        backward_compatible=True
                    ))
        
        return proposals
    
    def _find_missing_docstrings(self, file_path: Path, tree: ast.AST, code: str) -> List[RefactorProposal]:
        """
        –ù–∞–π—Ç–∏ —Ñ—É–Ω–∫—Ü–∏–∏ –±–µ–∑ docstrings.
        
        Args:
            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
            tree: AST –¥–µ—Ä–µ–≤–æ
            code: –ò—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥
        
        Returns:
            –°–ø–∏—Å–æ–∫ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        """
        proposals = []
        
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                docstring = ast.get_docstring(node)
                
                if not docstring and not node.name.startswith('_'):
                    proposals.append(RefactorProposal(
                        id=f"docstring_{file_path.stem}_{node.name}",
                        target_file=str(file_path),
                        refactor_type='document',
                        old_pattern=f"def {node.name}(",
                        new_pattern=f"def {node.name}(...):\n    \"\"\"Function description.\"\"\"",
                        reasoning="Add docstring for better documentation",
                        affected_lines=[node.lineno],
                        risk_score=0.05,
                        backward_compatible=True
                    ))
        
        return proposals
    
    def _find_legacy_patterns(self, file_path: Path, code: str) -> List[RefactorProposal]:
        """
        –ù–∞–π—Ç–∏ legacy patterns.
        
        Args:
            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
            code: –ò—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥
        
        Returns:
            –°–ø–∏—Å–æ–∫ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        """
        proposals = []
        
        lines = code.split('\n')
        
        # Check for old-style string formatting
        for i, line in enumerate(lines, 1):
            if '%s' in line or '%d' in line:
                if '"' in line or "'" in line:
                    proposals.append(RefactorProposal(
                        id=f"modernize_string_{file_path.stem}_{i}",
                        target_file=str(file_path),
                        refactor_type='modernize',
                        old_pattern=line.strip(),
                        new_pattern="Use f-strings instead",
                        reasoning="f-strings are more readable and faster",
                        affected_lines=[i],
                        risk_score=0.2,
                        backward_compatible=True
                    ))
        
        return proposals
    
    def _find_complex_functions(self, file_path: Path, tree: ast.AST, code: str) -> List[RefactorProposal]:
        """
        –ù–∞–π—Ç–∏ —Å–ª–∏—à–∫–æ–º —Å–ª–æ–∂–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏.
        
        Args:
            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
            tree: AST –¥–µ—Ä–µ–≤–æ
            code: –ò—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥
        
        Returns:
            –°–ø–∏—Å–æ–∫ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        """
        proposals = []
        
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                # Calculate complexity
                complexity = self._calculate_complexity(node)
                
                if complexity > 10:
                    proposals.append(RefactorProposal(
                        id=f"simplify_{file_path.stem}_{node.name}",
                        target_file=str(file_path),
                        refactor_type='simplify',
                        old_pattern=node.name,
                        new_pattern="Split into smaller functions",
                        reasoning=f"High complexity ({complexity}) makes code hard to maintain",
                        affected_lines=[node.lineno],
                        risk_score=0.4,
                        backward_compatible=True
                    ))
        
        return proposals
    
    def _calculate_complexity(self, node: ast.FunctionDef) -> int:
        """
        –í—ã—á–∏—Å–ª–∏—Ç—å cyclomatic complexity —Ñ—É–Ω–∫—Ü–∏–∏.
        
        Args:
            node: AST node —Ñ—É–Ω–∫—Ü–∏–∏
        
        Returns:
            Complexity score
        """
        complexity = 1
        
        for child in ast.walk(node):
            if isinstance(child, (ast.If, ast.While, ast.For, ast.ExceptHandler)):
                complexity += 1
            elif isinstance(child, ast.BoolOp):
                complexity += len(child.values) - 1
        
        return complexity
    
    def apply_refactor(self, proposal: RefactorProposal) -> bool:
        """
        –ü—Ä–∏–º–µ–Ω–∏—Ç—å —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥.
        
        Args:
            proposal: –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –ø–æ —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥—É
        
        Returns:
            True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ
        """
        logger.info(f"üîß Applying refactor: {proposal.id}")
        
        # Check backward compatibility
        if self.preserve_compatibility and not proposal.backward_compatible:
            logger.warning(f"   ‚ö†Ô∏è Skipping: breaks backward compatibility")
            return False
        
        # TODO: Implement actual refactoring
        # For now, just log
        logger.info(f"   Type: {proposal.refactor_type}")
        logger.info(f"   Risk: {proposal.risk_score:.2f}")
        logger.info(f"   Reasoning: {proposal.reasoning}")
        
        return True
    
    def generate_tests(self, file_path: Path) -> List[str]:
        """
        –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ç–µ—Å—Ç—ã –¥–ª—è —Ñ–∞–π–ª–∞.
        
        Args:
            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
        
        Returns:
            –°–ø–∏—Å–æ–∫ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤
        """
        logger.info(f"üß™ Generating tests for {file_path.name}...")
        
        tests = []
        
        try:
            code = file_path.read_text()
            tree = ast.parse(code)
            
            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef) and not node.name.startswith('_'):
                    # Generate basic test template
                    test_code = f"""
def test_{node.name}():
    \"\"\"Test {node.name} function.\"\"\"
    # TODO: Implement test
    pass
"""
                    tests.append(test_code)
        
        except Exception as e:
            logger.error(f"‚ùå Failed to generate tests: {e}")
        
        logger.info(f"   Generated {len(tests)} test templates")
        
        return tests
