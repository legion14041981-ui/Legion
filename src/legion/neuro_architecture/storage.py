"""
Storage Optimization - ÐºÐ¾Ð¼Ð¿Ð°ÐºÑ‚Ð½Ð¾Ðµ Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¹.

Ð’Ð´Ð¾Ñ…Ð½Ð¾Ð²Ð»ÐµÐ½Ð¾ Ñ„ÑƒÐ½Ð´Ð°Ð¼ÐµÐ½Ñ‚Ð°Ð»ÑŒÐ½Ñ‹Ð¼Ð¸ Ð¿Ñ€Ð¸Ð½Ñ†Ð¸Ð¿Ð°Ð¼Ð¸ Ð¿Ð°Ð¼ÑÑ‚Ð¸:
- Binary encoding Ð´Ð»Ñ ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ð¸
- ÐœÐ½Ð¾Ð³Ð¾ÑƒÑ€Ð¾Ð²Ð½ÐµÐ²Ñ‹Ð¹ ÐºÐµÑˆ (L1/L2/L3)
- Compression Ð´Ð»Ñ Ð´Ð¾Ð»Ð³Ð¾ÑÑ€Ð¾Ñ‡Ð½Ð¾Ð³Ð¾ Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ
"""

import json
import logging
from typing import Dict, Any, Optional
from pathlib import Path
import hashlib

logger = logging.getLogger(__name__)


class CompactConfigEncoder:
    """
    ÐšÐ¾Ð¼Ð¿Ð°ÐºÑ‚Ð½Ñ‹Ð¹ ÑÐ½ÐºÐ¾Ð´ÐµÑ€ Ð´Ð»Ñ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¹.
    
    Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ MessagePack Ð²Ð¼ÐµÑÑ‚Ð¾ JSON Ð´Ð»Ñ 70% ÑÐºÐ¾Ð½Ð¾Ð¼Ð¸Ð¸.
    """
    
    def __init__(self):
        try:
            import msgpack
            self.msgpack = msgpack
            self.available = True
        except ImportError:
            logger.warning("âš ï¸ msgpack not available, falling back to JSON")
            self.available = False
    
    def encode(self, config: Dict[str, Any]) -> bytes:
        """
        Ð—Ð°ÐºÐ¾Ð´Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸ÑŽ Ð² Ð±Ð°Ð¹Ñ‚Ñ‹.
        
        Args:
            config: ÐšÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ñ
        
        Returns:
            Ð‘Ð°Ð¹Ñ‚Ð¾Ð²Ð¾Ðµ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ
        """
        if self.available:
            return self.msgpack.packb(config)
        else:
            return json.dumps(config).encode('utf-8')
    
    def decode(self, data: bytes) -> Dict[str, Any]:
        """
        Ð”ÐµÐºÐ¾Ð´Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸ÑŽ Ð¸Ð· Ð±Ð°Ð¹Ñ‚Ð¾Ð².
        
        Args:
            data: Ð‘Ð°Ð¹Ñ‚Ð¾Ð²Ð¾Ðµ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ
        
        Returns:
            ÐšÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ñ
        """
        if self.available:
            return self.msgpack.unpackb(data, raw=False)
        else:
            return json.loads(data.decode('utf-8'))
    
    def estimate_savings(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """ÐžÑ†ÐµÐ½Ð¸Ñ‚ÑŒ ÑÐºÐ¾Ð½Ð¾Ð¼Ð¸ÑŽ Ð¼ÐµÑÑ‚Ð°."""
        json_size = len(json.dumps(config).encode('utf-8'))
        
        if self.available:
            msgpack_size = len(self.msgpack.packb(config))
            savings_pct = ((json_size - msgpack_size) / json_size) * 100
        else:
            msgpack_size = json_size
            savings_pct = 0.0
        
        return {
            'json_bytes': json_size,
            'msgpack_bytes': msgpack_size,
            'savings_percent': savings_pct
        }


class ArchitectureCache:
    """
    ÐœÐ½Ð¾Ð³Ð¾ÑƒÑ€Ð¾Ð²Ð½ÐµÐ²Ñ‹Ð¹ ÐºÐµÑˆ Ð´Ð»Ñ Ð°Ñ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€.
    
    L1 (Ð¿Ð°Ð¼ÑÑ‚ÑŒ): Ñ‚Ð¾Ð¿ 10 Ð°Ñ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€, fastest
    L2 (Redis/memcached): ÑÑ€ÐµÐ´Ð½Ð¸Ð¹ Ñ‚ÐµÑ€Ð¼Ð¸Ð½, fast
    L3 (Ð´Ð¸ÑÐº): Ð´Ð¾Ð»Ð³Ð¾ÑÑ€Ð¾Ñ‡Ð½Ð¾Ðµ Ñ…Ñ€Ð°Ð½Ð¸Ð»Ð¸Ñ‰Ðµ, slow
    """
    
    def __init__(self, storage_dir: str = "artifacts/cache"):
        """
        Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ ÐºÐµÑˆÐ°.
        
        Args:
            storage_dir: Ð”Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ñ Ð´Ð»Ñ L3 storage
        """
        self.storage_dir = Path(storage_dir)
        self.storage_dir.mkdir(parents=True, exist_ok=True)
        
        # L1: In-memory cache
        self.l1_cache: Dict[str, Any] = {}
        self.l1_max_size = 10
        
        # L2: Redis (ÐµÑÐ»Ð¸ Ð´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½)
        self.l2_available = self._init_l2()
        
        # Encoder
        self.encoder = CompactConfigEncoder()
        
        # Metrics
        self.hits = {'l1': 0, 'l2': 0, 'l3': 0}
        self.misses = 0
        
        logger.info(f"âœ… ArchitectureCache initialized")
        logger.info(f"   L1: {self.l1_max_size} slots (memory)")
        logger.info(f"   L2: {'enabled' if self.l2_available else 'disabled'} (redis)")
        logger.info(f"   L3: {storage_dir} (disk)")
    
    def _init_l2(self) -> bool:
        """Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ L2 cache (Redis)."""
        try:
            import redis
            self.l2_cache = redis.Redis(
                host='localhost',
                port=6379,
                db=0,
                decode_responses=False
            )
            # Test connection
            self.l2_cache.ping()
            return True
        except Exception as e:
            logger.info(f"L2 cache not available: {e}")
            return False
    
    def get(self, hash_id: str) -> Optional[Dict[str, Any]]:
        """
        ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð°Ñ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ñƒ Ð¸Ð· ÐºÐµÑˆÐ°.
        
        Args:
            hash_id: Semantic hash
        
        Returns:
            ÐšÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ñ Ð¸Ð»Ð¸ None
        """
        # Try L1
        if hash_id in self.l1_cache:
            self.hits['l1'] += 1
            logger.debug(f"âœ… L1 cache hit: {hash_id}")
            return self.l1_cache[hash_id]
        
        # Try L2
        if self.l2_available:
            try:
                cached = self.l2_cache.get(hash_id)
                if cached:
                    self.hits['l2'] += 1
                    config = self.encoder.decode(cached)
                    # Promote to L1
                    self._promote_to_l1(hash_id, config)
                    logger.debug(f"âœ… L2 cache hit: {hash_id}")
                    return config
            except Exception as e:
                logger.warning(f"L2 cache error: {e}")
        
        # Try L3 (disk)
        l3_path = self.storage_dir / f"{hash_id}.bin"
        if l3_path.exists():
            self.hits['l3'] += 1
            with open(l3_path, 'rb') as f:
                config = self.encoder.decode(f.read())
            # Promote to L2 and L1
            self._promote_to_l2(hash_id, config)
            self._promote_to_l1(hash_id, config)
            logger.debug(f"âœ… L3 cache hit: {hash_id}")
            return config
        
        # Cache miss
        self.misses += 1
        logger.debug(f"âŒ Cache miss: {hash_id}")
        return None
    
    def set(self, hash_id: str, config: Dict[str, Any], ttl: int = 3600) -> None:
        """
        Ð¡Ð¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ Ð°Ñ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ñƒ Ð² ÐºÐµÑˆ.
        
        Args:
            hash_id: Semantic hash
            config: ÐšÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ñ
            ttl: Time to live Ð´Ð»Ñ L2 (ÑÐµÐºÑƒÐ½Ð´Ñ‹)
        """
        # Write to all levels
        self._promote_to_l1(hash_id, config)
        self._promote_to_l2(hash_id, config, ttl)
        
        # Always persist to L3
        l3_path = self.storage_dir / f"{hash_id}.bin"
        with open(l3_path, 'wb') as f:
            f.write(self.encoder.encode(config))
        
        logger.debug(f"ðŸ’¾ Cached: {hash_id}")
    
    def _promote_to_l1(self, hash_id: str, config: Dict[str, Any]) -> None:
        """ÐŸÑ€Ð¾Ð´Ð²Ð¸Ð½ÑƒÑ‚ÑŒ Ð² L1 ÐºÐµÑˆ."""
        if len(self.l1_cache) >= self.l1_max_size:
            # Evict least recently used (FIFO for simplicity)
            oldest_key = next(iter(self.l1_cache))
            del self.l1_cache[oldest_key]
        
        self.l1_cache[hash_id] = config
    
    def _promote_to_l2(self, hash_id: str, config: Dict[str, Any], ttl: int = 3600) -> None:
        """ÐŸÑ€Ð¾Ð´Ð²Ð¸Ð½ÑƒÑ‚ÑŒ Ð² L2 ÐºÐµÑˆ."""
        if not self.l2_available:
            return
        
        try:
            self.l2_cache.setex(
                hash_id,
                ttl,
                self.encoder.encode(config)
            )
        except Exception as e:
            logger.warning(f"L2 cache write error: {e}")
    
    def get_stats(self) -> Dict[str, Any]:
        """ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ ÐºÐµÑˆÐ°."""
        total_requests = sum(self.hits.values()) + self.misses
        hit_rate = sum(self.hits.values()) / total_requests if total_requests > 0 else 0
        
        return {
            'total_requests': total_requests,
            'hits': self.hits,
            'misses': self.misses,
            'hit_rate': hit_rate,
            'l1_size': len(self.l1_cache),
            'l1_max_size': self.l1_max_size
        }
