"""
Proxy Trainer - Ð±Ñ‹ÑÑ‚Ñ€Ð¾Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¾ÐºÑÐ¸-Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹.

Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ LoRA/PEFT Ð´Ð»Ñ Ð¼Ð¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ.
ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ° Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ (vLLM, Ollama).
"""

import json
import logging
import time
from dataclasses import dataclass, asdict
from pathlib import Path
from typing import Dict, Any, Optional

logger = logging.getLogger(__name__)


@dataclass
class TrainingMetrics:
    """ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ."""
    proposal_id: str
    training_loss: float
    eval_accuracy: float
    latency_ms: float
    throughput_samples_sec: float
    gpu_memory_mb: float
    training_time_sec: float
    steps_completed: int
    
    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)
    
    def to_json(self) -> str:
        return json.dumps(self.to_dict(), indent=2)


class ProxyTrainer:
    """
    Proxy Trainer Ð´Ð»Ñ Ð±Ñ‹ÑÑ‚Ñ€Ð¾Ð³Ð¾ ÑÐºÑÐ¿ÐµÑ€Ð¸Ð¼ÐµÐ½Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ.
    
    ÐžÑÐ¾Ð±ÐµÐ½Ð½Ð¾ÑÑ‚Ð¸:
    - Quick training (2000-5000 steps)
    - ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ° LoRA/adapters
    - Ð›Ð¾ÐºÐ°Ð»ÑŒÐ½Ñ‹Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸
    - Metrics tracking
    """
    
    def __init__(self, proposal_id: str, config: Optional[Dict[str, Any]] = None):
        """
        Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ trainer.
        
        Args:
            proposal_id: ID Ð°Ñ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð½Ð¾Ð³Ð¾ proposal
            config: ÐšÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ
        """
        self.proposal_id = proposal_id
        self.config = config or {}
        logger.info(f"âœ… ProxyTrainer initialized for proposal '{proposal_id}'")
    
    def train(
        self,
        data_path: str,
        steps: int = 2000,
        output_dir: str = "artifacts/proxy_runs"
    ) -> TrainingMetrics:
        """
        Ð—Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚ÑŒ quick training.
        
        Args:
            data_path: ÐŸÑƒÑ‚ÑŒ Ðº Ð´Ð°Ð½Ð½Ñ‹Ð¼
            steps: ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ ÑˆÐ°Ð³Ð¾Ð²
            output_dir: Ð”Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ñ Ð´Ð»Ñ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²
        
        Returns:
            TrainingMetrics
        """
        logger.info(f"â–¶ï¸ Starting proxy training for '{self.proposal_id}' ({steps} steps)")
        start_time = time.time()
        
        # TODO: Ð˜Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ð¸Ñ Ñ PEFT/LoRA
        # ÐŸÐ¾ÐºÐ° ÑÐ¼ÑƒÐ»Ð¸Ñ€ÑƒÐµÐ¼ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ
        import random
        time.sleep(0.1)  # Simulate training
        
        # Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÐ¼ ÑÐ¸Ð½Ñ‚ÐµÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸
        metrics = TrainingMetrics(
            proposal_id=self.proposal_id,
            training_loss=random.uniform(0.5, 2.0),
            eval_accuracy=random.uniform(0.75, 0.95),
            latency_ms=random.uniform(20, 100),
            throughput_samples_sec=random.uniform(50, 200),
            gpu_memory_mb=random.uniform(2000, 8000),
            training_time_sec=time.time() - start_time,
            steps_completed=steps
        )
        
        # Ð¡Ð¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸
        self._save_metrics(metrics, output_dir)
        
        logger.info(f"âœ… Training completed: accuracy={metrics.eval_accuracy:.3f}, latency={metrics.latency_ms:.1f}ms")
        return metrics
    
    def _save_metrics(self, metrics: TrainingMetrics, output_dir: str) -> None:
        """Ð¡Ð¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð² Ñ„Ð°Ð¹Ð»."""
        run_dir = Path(output_dir) / self.proposal_id
        run_dir.mkdir(parents=True, exist_ok=True)
        
        metrics_file = run_dir / "metrics.json"
        with open(metrics_file, 'w') as f:
            f.write(metrics.to_json())
        
        logger.debug(f"ðŸ’¾ Metrics saved to {metrics_file}")
